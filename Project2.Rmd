---
title: "Assignment 2"
subtitle: "Moscholios Filippos-Michael, ΑΜ:F3352116"
output: html_notebook
---

```{r}
install.packages("tidyverse")
install.packages("lattice")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("readxl")
library("readxl")
library("reshape2")
library("lattice")
library("ggplot2")
library("tidyverse")
```


```{r}
df1 <- read.delim('salaries.txt',header=TRUE)
```
#### **Exercise 1** 
##### 1.

##### (a) After conducting t-test for the average salaries for men we are sure that the true mean for the variable of interest belongs to this interval CI:[31.85952 35.00412]
```{r}
t.test(df1$MALES, conf.level = 0.95)
```

##### (b) With the similar approach we construct the corresponding confidence interval for women: CI:[31.60332 34.79668]

```{r}
t.test(df1$FEMALES, conf.level = 0.95)
```
##### (c) To compute the CI for the mean difference of the average salary between males and females, because they are independent eachother, we conduct paired t.test. And the CI that results is  33.20000  33.43182 for 90% level of significance.
```{r}
t.test(df1$FEMALES,df1$MALES, conf.level = 0.9)
```
##### (d) For this task we conduct Hypothesis testing whi null hypothesis Ho:mu(female)=mu(male) with alternative H1: mu(female)<("less")mu(male). So observing the pvalue(0.4154)>a(0.05) we have evidence to reject the null hypothesis and consider that mean salary for women differ from mean salary for men and likely is less. 
```{r}
t.test(df1$FEMALES,df1$MALES,alternative = "less", conf.level = 0.95)
```
##### (e) Now to examine the equality of variances we conduct var.test and again we reject the null hypothesis that they are equal because pvalue(0.9445) is larger than 0.01.  
```{r}
var.test(df1$FEMALES,df1$MALES, conf.level = 0.99)
```
##### (f) To examine test if there is statistical effect of gender on average salaries we use melt function to group properly in the same dataframe the gender and the corresponding salary for each gender, and then we conduct the t.test for the value which describes the salary with variable which describes the gender, as factor. With pvalue(0.8307) we have enough evidence to reject the null hypothesis and considering that the gender affect the mean salary.
```{r}
dff<- melt(df1)
dff
t.test(dff$value~dff$variable, conf.level = 0.9)
```
#### **Exercise 2**

##### (a) After read our data, to prepare for for plotting and start fit our anova models properly we use the melt() function and store to the dataframe "data_long", at the column "value" the number of inquiries, at the column "Day" the days and at the column "variable" each section. So using ggplot library to construct the corresponding boxplot, we can understand and examine some useful facts as:                 1) Comparing the location of medians                                                                      2) Comparing the interquartile ranges (that is, the box lengths), to compare dispersion.                  3) Observing the overall spread as shown by the adjacent values.                                          4) And finally examining for signs of skewness and for potential outliers.                                    For our dataset we could for example report the outliers that appears on News category, large variance that appears on Business category at Tuesday, etc.
```{r}
df2<-read_excel("inquiries.xls")
df2
data_long
data_long<- melt(df2, "Day")
data_long
ggplot(data = data_long, aes(x=Day, y=value)) +geom_boxplot(aes(fill=variable))#https://stackoverflow.com/questions/14604439/plot-multiple-boxplot-in-one-graph
```

##### (b) Fit an One-Way ANOVA model with the number of inquiries as response and the days of the week (as factor). With fit_aov$coefficients we present it bellow the parameters of our model: 
```{r}
fit_aov<- aov(data_long$value~factor(data_long$Day))
summary(fit_aov)
fit_aov$coefficients
```
##### (c) To examine if the expected difference between Tuesdays and Wednesdays is significant we conduct Tukey test for our model and realize with the pval(0.9959087)>a(0.05) the difference for these days is not statistically significant.
```{r}
TukeyHSD(fit_aov)#after obesrving the pvalue=0.995>0.05 from Tukey method we realize that the difference is not statistically significant 

```

##### (d) For this question we store to fit2_aov the model for the number of inquiries as response and sections. To begin with, if we notice the summary for our model we observe that all sections(variable) are statistically important, therefore we have to check  with more precision if there are some variable that is not significant. Firstly we present the models parameters with fit2_aov$coefficients. And finally, We conduct Tukey test and realize that the comparison of each section with News is not statistically significant because they are differ with pvalue(0.9658594) the comparison with Business and pvalue(0.0525040) with Sports. Those pvalues are larger than 0.05 which is the level of significance for our test.


```{r}
fit2_aov<- aov(data_long$value~data_long$variable)
summary(fit2_aov)
fit2_aov$coefficients
```

```{r}
TukeyHSD(fit2_aov)
```
##### (e) At this part after examining that the parameter News is not statistically significant we excluding it and re-estimate the parameters of our model. We create a dataframe with only the statistically signifacnt parameters called data_significant and present bellow the coefficients of our model called fit_aov_e with the command fit_aov_e$coefficients

```{r}
data_significant <- filter(data_long, variable != "News")
data_significant
fit_aov_e<- aov(data=data_significant,value~variable)
fit_aov_e$coefficients
#interpretation of parameters```
```
##### (f) We store at Two_way_aov the model with the main effects whie are Day+variable(sections), and we present bellow the parameters.
```{r}
Two_way_aov <- aov(value ~ Day+variable, data = data_long)
Two_way_aov$coefficients#interpretation of parameters of  two way anova 
```

##### (g) To construct the model of full main effects we store at full_main_model and fir to anova model  the product of Day and variable(section) to take into account all the possible combinations between Day and sections. Not only the product but also the sum between them. After with the step() method we can understant with AIC(45.506) which includes all the parameters has the better performance. In sequel, with summary of our model we can verify the above result because all of our parameters are statistically significant and present the coefficients with aic_full_main$coefficients. Finally to examine with more precision if are all coefficients significant, we conduct Tukey test. And we can be confidence for 95% that the combinations which give us pvalue more than 0.05 are not statistically significant.
```{r}
full_main_model <- aov(value ~ Day*variable, data = data_long)
aic_full_main <- step(full_main_model)
```


```{r}
summary(full_main_model)
```


```{r}
aic_full_main$coefficients

```


```{r}
TukeyHSD(aic_full_main)
```
##### (h) We create the main_model which include only the sum as combination between variable(section) and Day. Also, we create the constant_model and finally taking the Anova between our two models with pvalue=2.536e-06<0.05 we have strong evidence against null hypothesis, so we fail to reject null hypothesis that our models are equal.
```{r}
main_model <- aov(value ~ Day+variable, data = data_long)
constant_model<-aov(data=data_long,value ~ 1)
anova(constant.model,main.model)
```


